# Langfuse Self-hosted (docker compose --profile langfuse up -d)
LANGFUSE_PUBLIC_KEY=pk-lf-lm-stack-local
LANGFUSE_SECRET_KEY=sk-lf-lm-stack-local
LANGFUSE_HOST=http://localhost:3000
# FÃ¼r Langfuse Cloud stattdessen:
# LANGFUSE_PUBLIC_KEY=pk-lf-...
# LANGFUSE_SECRET_KEY=sk-lf-...
# LANGFUSE_HOST=https://cloud.langfuse.com

# LM Studio (Qwen3, OpenAI-kompatible API)
LM_STUDIO_BASE_URL=http://localhost:1234/v1
LM_STUDIO_MODEL=qwen/qwen3-8b
# Falls kein LM Studio: Ollama-Fallback
OLLAMA_BASE_URL=http://localhost:11434/v1
OLLAMA_MODEL=qwen/qwen3-8b
